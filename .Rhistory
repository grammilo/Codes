plot.enet(lasso$finalModel, xvar = "penalty", use.color = TRUE)
library(lubridate)
library(readr)
dat <- read_csv("C:/Users/piyus/Desktop/gaData.csv")
View(dat)
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
tstrain
?ts
View(dat)
attach(dat)
plot(date,visitsTumblr)
library(forecast)
mod_ts <- bats(tstrain)
install.packages("forecast")
library(forecast)
mod_ts <- bats(tstrain)
fcast <- forecast(mod_ts, level = 95, h = dim(testing)[1])
head(fcast)
dim(training)
dd<-data.frame(fcast$lower,fcast,fcast$upper)
head(dd)
head(fcast$lower)
str(fcast)
sum(fcast$lower < testing$visitsTumblr & testing$visitsTumblr < fcast$upper) /
dim(testing)[1]
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
install.packages(e1071); library(e1071)
install.packages(e1071)
install.packages("e1071")
install.packages("e1071")
names(training)
mod_svm<-svm(CompressiveStrength ~ ., data = training)
pred_svm<-predict(mod_svm,testing)
accuracy(pred_svm,testing$CompressiveStrength)
rm(list=ls())
library(readr)
training <- read_csv("C:/Users/piyus/Desktop/pml-training.csv")
View(training)
names(training)
order(names(training), decreasing = TRUE)
order(names(training), decreasing = FALSE)
names(order(names(training), decreasing = FALSE))
names(training)[order(names(training), decreasing = FALSE)]
view(head(training))
view(training)
View(training)
training[,"classe"]
View(training)
names(training)
names(training)[order(names(training), decreasing = FALSE)]
order(names(training), decreasing = FALSE)
training[,c(160)]
View(training[,160])
View(training[,c(160,1:159)])
library(readr)
pml_testing <- read_csv("C:/Users/piyus/Desktop/pml-testing.csv")
View(pml_testing)
rm(pml_testing)
library(readr)
testing <- read_csv("C:/Users/piyus/Desktop/pml-testing.csv")
View(testing)
is.na(training)
propNAs <- colMeans(is.na(training))
table(propNAs)
require(caret)
require(corrplot)
require(Rtsne)
require(xgboost)
require(stats)
require(knitr)
require(ggplot2)
install.packages(Rtsne)
install.packages(xgboost)
install.packages("Rtsne")
install.packages("xgboost")
require(caret)
require(corrplot)
require(Rtsne)
require(xgboost)
require(stats)
require(knitr)
require(ggplot2)
outcome.org = training[, "classe"]
outcome = outcome.org
levels(outcome)
levels(training$classe)
View(training)
testing <- read_csv("C:/Users/piyus/Desktop/pml-testing.csv")
training <- read_csv("C:/Users/piyus/Desktop/pml-training.csv")
outcome.org = training[, "classe"]
View(outcome.org)
levels(outcome.org)
unique(outcome.org)
?levels
outcome.org = data.frame(training[, "classe"])
outcome = outcome.org
unique(outcome.org)
rm(outcome)
rm(outcome.org)
rm(propNAs)
View(training)
sumamry(training)
summary(training)
dim(training)
summary(training)
training_red<-training[,-c(1:5)]
summary(training_red)
training_red[,1]
s.na(training_red[,1])
is.na(training_red[,1])
names(training_red)
order(names(training_red),decreasing = FALSE)
names(training_red)$order(names(training_red),decreasing = FALSE)
names(training_red)order(names(training_red),decreasing = FALSE)
names(training_red)[order(names(training_red),decreasing = FALSE)]
names(training_red)[order(names(training_red),decreasing = FALSE)]
order(names(training_red),decreasing = FALSE)
col<-names<-names(training_red)[order(names(training_red),decreasing = FALSE)]
col_order<-order(names(training_red),decreasing = FALSE)
col_names<-names(training_red)[order(names(training_red),decreasing = FALSE)]
col_order<-order(names(training_red),decreasing = FALSE)
all_cols_pos<-data.frame(cbind(col_names,col_order))
View(all_cols_pos)
all_cols_pos[all_cols_pos$col_names = "classe",]
all_cols_pos[all_cols_pos$col_names == "classe",]
all_cols_pos[all_cols_pos$col_names == "classe",][2]
all_cols_pos[all_cols_pos$col_names == "classe",][[2]]
all_cols_pos[all_cols_pos$col_names == "classe",][[2]][1]
all_cols_pos[all_cols_pos$col_names == "classe",][[2]][[1]]
all_cols_pos[all_cols_pos$col_names == "classe",]
i=1
is.na(training_red[,i])
sum(is.na(training_red[,i]))
dim(training_red)[2]
dim(training_red)[1]
sum(is.na(training_red[,i]))/dim(training_red)[1]
dim(training_red)[1]-1
dim(training_red)[2]
dim(training_red)[2]-1
for (j in 1:dim(training_red)[2]-1){
for (i in 1:dim(training_red)[1]){
col_checks_NA<-data.frame(order = j
,
prop_NA<-sum(is.na(training_red[,i]))/dim(training_red)[1]
)
}
}
for (j in 1:dim(training_red)[2]){
for (i in 1:dim(training_red)[1]){
col_checks_NA<-data.frame(order = j
,
prop_NA<-sum(is.na(training_red[,i]))/dim(training_red)[1]
)
}
}
for (i in 1:dim(training_red)[1]){
col_checks_NA<-data.frame(order = j
,
prop_NA<-sum(is.na(training_red[,i]))/dim(training_red)[1]
)
}
for (i in 1:dim(training_red)[1]){
col_checks_NA<-data.frame("order" = j
,
"prop_NA"=sum(is.na(training_red[,i]))/dim(training_red)[1]
)
}
prop_NA<-vector()
for (j in 1:dim(training_red)[2]-1)
{
for (i in 1:dim(training_red)[1])
{
prop_NA<-sum(is.na(training_red[,i]))/dim(training_red)[1]
}
}
for (i in 1:dim(training_red)[1])
{
prop_NA<-sum(is.na(training_red[,i]))/dim(training_red)[1]
}
dim(training_red)[1]
i=1
for (i in 1:dim(training_red)[1])
{
prop_NA<-sum(is.na(training_red[,i]))/dim(training_red)[1]
}
dim(training_red)[1]
for (i in 1:dim(training_red)[2])
{
prop_NA<-sum(is.na(training_red[,i]))/dim(training_red)[1]
}
prop_NA
for (i in 1:dim(training_red)[2]-1)
{
prop_NA<-sum(is.na(training_red[,i]))/dim(training_red)[1]
}
prop_NA
all_cols_pos[all_cols_pos$col_names == "amplitude_roll_arm",]
prop_NA<-sum(is.na(training_red[,76]))/dim(training_red)[1]
for (i in 1:dim(training_red)[2]-1)
{
prop_NA[i]<-sum(is.na(training_red[,i]))/dim(training_red)[1]
}
prop_NA
for (i in 1:dim(training_red)[2]-1)
{
order<-i
prop_NA[i]<-sum(is.na(training_red[,i]))/dim(training_red)[1]
col_checks_NA<-data.frame(cbind(order,prop_NA[i]))
}
col_checks_NA
for (i in 1:dim(training_red)[2]-1)
{
order<-i
prop_NA[i]<-sum(is.na(training_red[,i]))/dim(training_red)[1]
col_checks_NA[i]<-cbind(order,prop_NA[i])
}
for (i in 1:dim(training_red)[2]-1)
{
order<-i
prop_NA[i]<-sum(is.na(training_red[,i]))/dim(training_red)[1]
col_checks_NA[i]<-data.frame(cbind(order,prop_NA[i]))
}
prop_NA<-vector()
order<-vector()
for (i in 1:dim(training_red)[2]-1)
{
order<-i
prop_NA[i]<-sum(is.na(training_red[,i]))/dim(training_red)[1]
}
prop_NA<-vector()
order<-vector()
for (i in 1:dim(training_red)[2]-1)
{
order[i]<-i
prop_NA[i]<-sum(is.na(training_red[,i]))/dim(training_red)[1]
}
col_checks_NA<-data.frame()
for (i in 1:dim(training_red)[2]-1)
{
order[i]<-i
prop_NA[i]<-sum(is.na(training_red[,i]))/dim(training_red)[1]
col_checks_NA[i]<-data.frame(cbind(order[i],prop_NA[i]))
}
col_checks_NA<-data.frame(cbind(order,prop_NA))
prop_NA<-vector()
order<-vector()
for (i in 1:dim(training_red)[2]-1)
{
order[i]<-i
prop_NA[i]<-round(sum(is.na(training_red[,i]))/dim(training_red)[1],3)
}
col_checks_NA<-data.frame(cbind(order,prop_NA))
col_checks_NA[col_checks_NA$prop_NA==0,]
x<-col_checks_NA[col_checks_NA$prop_NA==0,]
x
View(training_red)
x<-col_checks_NA[col_checks_NA$prop_NA>0.5,] #Columns where proportion of NAs is >0.5
x
nrow(x)
training_red_final<-
x[,1]
training_red_final<-
x[,1]
x[,1]
c(x[,1])
training_red_final<-training_red[,-c(x[,1])]
View(training_red_final)
library(corrplot)
str(training_red_final)
summary(training_red_final)
testing_red<-testing[,-c(1:5)]
testing_red_final<-testing_red[,-c(x[,1])]
nearZeroVar(training_red_final)
zero_var<-nearZeroVar(training_red_final,saveMetrics = TRUE)
nearZeroVar(training_red_final,saveMetrics = TRUE)
training_red_final<-training_red_final[,-c(1,2)]
testing_red_final<-testing_red_final[,-c(1,2)]
View(testing_red_final)
M<-corrplot(training_red_final)
head(training_red_final)
View(training_red_final)
M<-corrplot(training_red_final[,-c(55)])
training_red_final[,c(55)]
training_red_final[,-c(55)]
training_red_final[,-c(55)]
training_red_final[,-55]
dim(training_red_final)
training_red_final[,-53]
corrplot(training_red_final[,-53], type = "upper", order = "hclust",
tl.col = "black", tl.srt = 45)
#Reading the dataset
testing <- read_csv("C:/Users/piyus/Desktop/pml-testing.csv")
training <- read_csv("C:/Users/piyus/Desktop/pml-training.csv")
#Dimensions of training
dim(training)
#Position of "classe" column (outcome) = 155
col_names<-names(training_red)[order(names(training_red),decreasing = FALSE)]
col_order<-order(names(training_red),decreasing = FALSE)
all_cols_pos<-data.frame(cbind(col_names,col_order))
all_cols_pos[all_cols_pos$col_names == "classe",]
#Removing first 5 columns because they are not helpful in prediction
training_red<-training[,-c(1:5)]
testing_red<-testing[,-c(1:5)]
#Summary of training
#Reveals presence of many columns with NAs
summary(training_red)
#Removing columns with NA
prop_NA<-vector()
order<-vector()
for (i in 1:dim(training_red)[2]-1)
{
order[i]<-i
prop_NA[i]<-round(sum(is.na(training_red[,i]))/dim(training_red)[1],3)
}
col_checks_NA<-data.frame(cbind(order,prop_NA))
x<-col_checks_NA[col_checks_NA$prop_NA>0.5,] #Columns where proportion of NAs is too much >0.5, 100 columns
training_red_final<-training_red[,-c(x[,1])]
testing_red_final<-testing_red[,-c(x[,1])]
#Checking variance among predictors, in case we need a PCA preprocessing
zero_var<-nearZeroVar(training_red_final,saveMetrics = TRUE)
#Removing new_window as it has zero variance
#Also num_window because percentUnique is too low
training_red_final<-training_red_final[,-c(1,2)]
testing_red_final<-testing_red_final[,-c(1,2)]
rm(list=ls())
#Reading the dataset
testing <- read_csv("C:/Users/piyus/Desktop/pml-testing.csv")
training <- read_csv("C:/Users/piyus/Desktop/pml-training.csv")
#Dimensions of training
dim(training)
#Position of "classe" column (outcome) = 155
col_names<-names(training_red)[order(names(training_red),decreasing = FALSE)]
col_order<-order(names(training_red),decreasing = FALSE)
all_cols_pos<-data.frame(cbind(col_names,col_order))
all_cols_pos[all_cols_pos$col_names == "classe",]
#Removing first 5 columns because they are not helpful in prediction
training_red<-training[,-c(1:5)]
testing_red<-testing[,-c(1:5)]
#Removing columns with NA
prop_NA<-vector()
order<-vector()
for (i in 1:dim(training_red)[2]-1)
{
order[i]<-i
prop_NA[i]<-round(sum(is.na(training_red[,i]))/dim(training_red)[1],3)
}
col_checks_NA<-data.frame(cbind(order,prop_NA))
x<-col_checks_NA[col_checks_NA$prop_NA>0.5,] #Columns where proportion of NAs is too much >0.5, 100 columns
training_red_final<-training_red[,-c(x[,1])]
testing_red_final<-testing_red[,-c(x[,1])]
#Checking variance among predictors, in case we need a PCA preprocessing
zero_var<-nearZeroVar(training_red_final,saveMetrics = TRUE)
#Removing new_window as it has zero variance
#Also num_window because percentUnique is too low
training_red_final<-training_red_final[,-c(1,2)]
testing_red_final<-testing_red_final[,-c(1,2)]
library(corrplot)
View(training_red_final)
res<-cor(training_red_final[,-53])
corrplot(res, type = "upper", order = "hclust", tl.col = "black", tl.srt = 45)
str(res)
res
View(res)
View(training_red_final)
is.na(training_red_final)
sum(is.na(training_red_final))
sum(is.na(testing_red_final))
training_red_final2<-training_red_final[!is.na(training_red_final),]
training_red_final2<-training_red_final[is.not.na(training_red_final),]
?is.not.na
training_red_final2<-training_red_final[is.na(training_red_final)==0,]
rm(training_red_final2)
training_red_final2<-training_red_final[is.na(training_red_final)==0,]
1039963/19622
training_red_final2<-training_red_final[complete.cases(training_red_final),]
complete.cases(training_red_final)
sum(complete.cases(training_red_final))
complete.cases(training_red_final)==0
training_red_final[complete.cases(training_red_final)==0,]
which(complete.cases(training_red_final)==0)
training_red_final2<-training_red_final[complete.cases(training_red_final),]
res<-cor(training_red_final2[,-53])
View(res)
corrplot(res, type = "upper", order = "hclust")
data.frame(res)
kK<-data.frame(res)
View(kK)
View(col_checks_NA)
col_names<-names(training_red)[order(names(training_red),decreasing = FALSE)]
col_order<-order(names(training_red),decreasing = FALSE)
all_cols_pos<-data.frame(cbind(col_names,col_order))
all_cols_pos[all_cols_pos$col_names == "classe",]
View(all_cols_pos)
training_red_final3<-training_red_final2[,-c(37,59,5,38)]
col_names<-names(training_red_final2)[order(names(training_red_final2),decreasing = FALSE)]
col_order<-order(names(training_red_final2),decreasing = FALSE)
all_cols_pos<-data.frame(cbind(col_names,col_order))
View(training_red_final2)
training_red_final3<-training_red_final2[,-c(10,22,3,11)]
library(caret)
View(testing_red_final)
testing_red_final3<-testing_red_final[,-c(10,22,3,11)]
View(training_red_final3)
View(all_cols_pos)
mod_rf<-train(classe ~ .,data = training_red_final3, method = "rf")
View(training_red_final3)
mod_gbm<-train(classe ~ .,data = training_red_final3, method = "gbm")
mod_lda<-train(classe ~ .,data = training_red_final3, method = "lda")
pred_rf<-predict(mod_rf,training_red_final3)
?confusionMatrix
pred_rf
confusionMatrix(pred_rf,training_red_final3$classe)
pred_gbm<-predict(mod_gbm,training_red_final3)
confusionMatrix(pred_gbm,training_red_final3$classe)
pred_lda<-predict(mod_lda,training_red_final3)
confusionMatrix(pred_lda,training_red_final3$classe)
View(training_red_final3)
View(testing_red_final3)
names(training)
names(training_red_final3)
order(names(training_red_final3), decreasing = FALSE)
names(training_red_final3)[order(names(training_red_final3), decreasing = FALSE)]
pred_test<-predict(mod_rf,testing_red_final3)
pred_test
table(pred_test)
prop.table(pred_test)
prop.table(pred_test,1)
prop.table(pred_test,2)
str(pred_test)
pred_test<-data.frame(pred_test)
prop.table(pred_test,1)
prop.table(pred_test,2)
prop.table(pred_test)
View(pred_test)
?prp
varImp(mod_rf)
?varImp
varImp(mod_rf)
str(mod_rf)
plot(mod_rf)
install.packages(ggraph)
install.packages("ggraph")
library(ggraph)
ggraph(mod_rf,'dendrogram')
?ggraph
as.dendrogram(mod_rf)
getTree(mod_rf)
?getTree
library(randomForest)
getTree(mod_rf)
plot(mod_rf)
fancyrplot
?fancyrplot
library(rattle)
fancyRpartPlot(mod_rf)
plot.rf.tree(mod_rf)
install.packages("tree")
plot.rf.tree(mod_rf)
library("tree")
plot.rf.tree(mod_rf)
plot.randomForest(mod_rf)
?plot.randomForest
library("randomForest")
plot.randomForest(mod_rf)
install.packages("randomForest")
install.packages("randomForest")
intrain<-createDataPartition(,data = training_red_final3, p = 0.6, list = TRUE)
intrain<-createDataPartition(classe,data = training_red_final3, p = 0.6, list = FALSE)
intrain<-createDataPartition(training_red_final3$classe, p = 0.6, list = FALSE)
intrain
train_obj<-createDataPartition(training_red_final3$classe, p = 0.6, list = FALSE)
intrain<-training_red_final3[train_obj,]
intest<-training_red_final3[-train_obj,]
system.time(mod_rf<-train(classe ~ .,data = intrain,method = "rf"))
View(training_red_final3)
system.time(mod_rf<-train(classe ~ .,data = intrain,method = "rf"))
system.time(mod_gbm<-train(classe ~ .,data = intrain,method = "gbm"))
system.time(mod_lda<-train(classe ~ .,data = intrain,method = "lda"))
pred_rf<-predict(mod_rf,intest)
confusionMatrix(pred_rf,intest$classe)
pred_gbm<-predict(mod_gbm,intest)
confusionMatrix(pred_gbm,intest$classe)
pred_lda<-predict(mod_lda,intest)
confusionMatrix(pred_lda,intest$classe)
pred_testing<-predict(mod_rf,testing_red_final3)
pred_testing
varImp(pred_testing)
varImp(mod_rf)
set.seed(123)
install.packages("rmarkdown", type = "source")
install.packages("rmarkdown", type = "source")
install.packages("rmarkdown", type = "source")
install.packages("rmarkdown")
unlink('C:/Users/piyus/Desktop/Practical Machine Learning Peer Project_cache', recursive = TRUE)
knit_with_parameters('C:/Users/piyus/Desktop/Practical Machine Learning Peer Project.Rmd')
unlink('C:/Users/piyus/Desktop/Practical Machine Learning Peer Project_cache', recursive = TRUE)
summary(cars)
plot(pressure)
unlink('C:/Users/piyus/Desktop/Practical Machine Learning Peer Project_cache', recursive = TRUE)
pred_testing
library("rmarkdown")
library("knitr")
unlink('HW6 Q1&2_cache', recursive = TRUE)
version
