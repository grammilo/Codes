---
title: "Practical Machine Learning Project: Identifying the quality of exercise from device data"
author: "Piyush Verma"
date: "December 20, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# {.tabset}

## Introduction

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement - a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, our goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways.

#### Data 
The data for this project come from this source: http://groupware.les.inf.puc-rio.br/har. If you use the document 

## Data Cleaning

Loading up the required libraries and the data. 
```{r echo=FALSE, warning=FALSE}
library(corrplot)
library(caret)
library(readr)
set.seed(123)
#Reading the dataset
testing <- read_csv("C:/Users/piyus/Desktop/pml-testing.csv")
training <- read_csv("C:/Users/piyus/Desktop/pml-training.csv")
#Dimensions of training
dim(training)
```

Creating a temporary table, kind of a legend to look and refer predictors (since there are 160 in total in training)
```{r}
#Position of "classe" column (outcome) = 155
col_names<-names(training)[order(names(training),decreasing = FALSE)]
col_order<-order(names(training),decreasing = FALSE)
all_cols_pos<-data.frame(cbind(col_names,col_order))
all_cols_pos[all_cols_pos$col_names == "classe",]
```

By looking into the data we can say that the first 5 columns will not be any helpful for predicting the response "classe". So we will delete them.
```{r}
#Removing first 5 columns because they are not helpful in prediction
training_red<-training[,-c(1:5)]
testing_red<-testing[,-c(1:5)]
```

A quick look of summary tells us that there are many other columns which have lots of NAs and thus need to be investigated futher for their removal (removal of only the columns which have substantial NAs and thus can't be imputed)
```{r eval = FALSE}
#Summary of training
#Reveals presence of many columns with NAs
summary(training_red)
```
```{r}
#Removing columns with NA
prop_NA<-vector()
order<-vector()
      for (i in 1:dim(training_red)[2]-1)
      {
      order[i]<-i  
      prop_NA[i]<-round(sum(is.na(training_red[,i]))/dim(training_red)[1],3)
      }
col_checks_NA<-data.frame(cbind(order,prop_NA))
x<-col_checks_NA[col_checks_NA$prop_NA>0.5,] #Columns where proportion of NAs is too much >0.5, 100 columns
training_red_final<-training_red[,-c(x[,1])]
testing_red_final<-testing_red[,-c(x[,1])]
```

After getting rid of columns/variables  with more than half of NAs, we will do a check on all the variables if they have enough variance, since variables which have less variance will give less information. We found that the predictor "new_window" has almost zero variance and thus it also should be removed.
```{r}
#Checking variance among predictors, in case we need a PCA preprocessing
zero_var<-nearZeroVar(training_red_final,saveMetrics = TRUE)
```
Removing of "new_window" & "num_window":
```{r}
#Removing new_window as it has zero variance 
#Also num_window because percentUnique is too low
training_red_final<-training_red_final[,-c(1,2)]
testing_red_final<-testing_red_final[,-c(1,2)]
```


We still find that there are 3 rows where some cells are NA. Because we cant calculate correlation, 
we will remove these observations
```{r}
sum(is.na(training_red_final)) #training has 3 observations
sum(is.na(testing_red_final)) #testing has zero such observations

training_red_final2<-training_red_final[complete.cases(training_red_final),]
#5373 observation in training_red_final above had 3 NAs
which(complete.cases(training_red_final)==0)
```

## Analysis

#### Correlation

Checking independence of predictors
```{r}
res<-cor(training_red_final2[,-53])
corrplot(res, type = "upper", order = "hclust")
```

From the corrplot we can say that predictors like acc_belt_z is highly -vely correlated to acc_belt_y and 2 others and hence multi-collinearity exists. Based on manual selection, we will be removing following columns because of their correlation with other predictors (Left-COlumn name : Righ-Their position in training_red_final2 table)
```{r}
#---accel_belt_z 10
#---accel_arm_y 22
#---yaw_belt 3
#---magnet_belt_x 11
training_red_final3<-training_red_final2[,-c(10,22,3,11)]
testing_red_final3<-testing_red_final[,-c(10,22,3,11)]
```

#### Final Model
Creating training and testing dataset within original training dataset to look at out of sample error rates from 3 different models: Random forest, gradient boost model and linear discriminant analysis
```{r eval=FALSE, echo = TRUE}
train_obj<-createDataPartition(training_red_final3$classe, p = 0.6, list = FALSE)
intrain<-training_red_final3[train_obj,]
intest<-training_red_final3[-train_obj,]

system.time(mod_rf<-train(classe ~ .,data = intrain,method = "rf"))
system.time(mod_gbm<-train(classe ~ .,data = intrain,method = "gbm"))
system.time(mod_lda<-train(classe ~ .,data = intrain,method = "lda"))


pred_rf<-predict(mod_rf,intest)
confusionMatrix(pred_rf,intest$classe)
#Accuracy : 0.9874

pred_gbm<-predict(mod_gbm,intest)
confusionMatrix(pred_gbm,intest$classe)
#Accuracy : 0.9517 

pred_lda<-predict(mod_lda,intest)
confusionMatrix(pred_lda,intest$classe)
#Accuracy : 0.6868

pred_testing<-predict(mod_rf,testing_red_final3)
```

Since random forest gave us the best out of sample accuracy, we will be using the model on final testing dataset.
```{r eval = FALSE}
pred_testing
```
 
 [1] B A B A A E D B A A B C B A E E A B B B

Levels: A B C D E

Following are the top predictors by their importance: 
```{r}
varImp(mod_rf)
```
rf variable importance

  only 20 most important variables shown (out of 48)

                     Overall
roll_belt            100.000
pitch_forearm         52.494
roll_forearm          41.612
magnet_dumbbell_z     40.640
pitch_belt            38.441
magnet_dumbbell_y     38.312
accel_dumbbell_y      21.101
roll_dumbbell         16.575
magnet_belt_y         15.725
magnet_belt_z         15.302
accel_forearm_x       14.183
magnet_dumbbell_x     13.822
accel_dumbbell_z      12.952
total_accel_dumbbell  12.828
magnet_forearm_z      12.727
gyros_belt_z           9.316
accel_forearm_z        8.351
roll_arm               7.768
gyros_dumbbell_y       7.607
yaw_dumbbell           7.043

## Source of the data

Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13). Stuttgart, Germany: ACM SIGCHI, 2013.

